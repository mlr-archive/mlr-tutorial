# Learners
The following classes provide a unified interface to all popular machine learning methods in **R**:
(cost-sensitive) classification, regression, survival analysis, and clustering.
Many are already integrated, and [%mlr] is specifically designed to make extensions simple.

See the [integrated learners page](integrated_learners.md) to reference already
implemented machine learning methods and their properties.
If your favorite method is missing, either [open an issue](https://github.com/mlr-org/mlr/issues) or
[integrate a learning method yourself](create_learner.md).

This basic introduction demonstrates how to use already implemented learners.


## Constructing a learner
A learner in [%mlr] is generated by calling [&makeLearner].
In the constructor, you need to specify which learning method you want to use.
You may also:

* Set hyperparameters
* Control the prediction output type, e.g., for classification
  whether you want a factor of predicted class labels or probabilities.
* Set an ID to name the object (some methods will later use this ID to label results or annotate plots).

```{r}
## Classification tree, set it up for predicting probabilities
classif.lrn = makeLearner("classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)

## Regression gradient boosting machine, specify hyperparameters via a list
regr.lrn = makeLearner("regr.gbm", par.vals = list(n.trees = 500, interaction.depth = 3))

## Cox proportional hazards model with custom name
surv.lrn = makeLearner("surv.coxph", id = "cph")

## K-means with 5 clusters
cluster.lrn = makeLearner("cluster.kmeans", centers = 5)

## Multilabel Random Ferns classification algorithm
multilabel.lrn = makeLearner("multilabel.rFerns")
```

The first argument specifies which algorithm to use.
The naming convention is ``classif.<R_method_name>`` for
classification methods, ``regr.<R_method_name>`` for regression methods,
``surv.<R_method_name>`` for survival analysis, ``cluster.<R_method_name>``
for clustering methods, and ``multilabel.<R_method_name>`` for multilabel classification.

Hyperparameter values can be specified either via the ``...`` argument or as a [list](&base::list)
via ``par.vals``.

Occasionally, [factor](&base::factor) features may cause problems when fewer levels are present in the
test data set than in the training data.
We can avoid this by setting ``fix.factors.prediction = TRUE`` to add a factor level for missing data in the test data set.

Let's have a look at two of the learners created above:

```{r}
classif.lrn

surv.lrn
```

All generated learners are objects of class [Learner](&makeLearner).
This class contains the properties of the method, e.g., which types of features it can handle,
what kind of output is possible during prediction, and whether multi-class problems,
observations weights or missing values are supported.

There is currently no special learner class for cost-sensitive classification.
For ordinary misclassification costs, you can use standard classification methods.
For example-dependent costs, there are several ways to generate cost-sensitive learners from ordinary
regression and classification learners. This is explained in greater detail in the
[cost-sensitive classification tutorial](cost_sensitive_classif.md).


## Accessing a learner
The [Learner](&makeLearner) object is a [list](&base::list) and the following elements contain
information regarding the hyperparameters and the type of prediction.

```{r}
## Get the configured hyperparameter settings that deviate from the defaults
cluster.lrn$par.vals

## Get the set of hyperparameters
classif.lrn$par.set

## Get the type of prediction
regr.lrn$predict.type
```

Slot ``$par.set`` is an object of class [ParamSet](&ParamHelpers::makeParamSet)
containing the type of hyperparameters (e.g., numeric, logical), potential
default values and the range of allowed values.

[%mlr] provides function [&getHyperPars] or its alternative [&getLearnerParVals] to access the current hyperparameter setting
of a [Learner](&makeLearner) and [&getParamSet] to get a description of all possible settings.

These are particularly useful with wrapped [Learner](&makeLearner)s,
such as a learner fused with a feature selection strategy, where both the learner and feature selection strategy
have hyperparameters. For details see the [wrapped learners tutorial](wrapper.md).

```{r}
## Get current hyperparameter settings
getHyperPars(cluster.lrn)

## Get a description of all possible hyperparameter settings
getParamSet(classif.lrn)
```

We can also use [&getParamSet] or its alias [&getLearnerParamSet] to get a quick overview about the available
hyperparameters and defaults of a learning method without explicitly constructing it (by calling [&makeLearner]).

```{r}
getParamSet("classif.randomForest")
```

Functions for accessing a Learner's meta information are available in [%mlr]. We can use [&getLearnerId], [&getLearnerShortName] and  [&getLearnerType]. To show the required packages for a Learner, use
[&getLearnerPackages].

```{r}
## Get object's id
getLearnerId(surv.lrn)

## Get the short name
getLearnerShortName(classif.lrn)

## Get the type of the learner
getLearnerType(multilabel.lrn)

## Get required packages
getLearnerPackages(cluster.lrn)
```

## Modifying a learner

We also provide functions that enable you to change certain aspects
of a [Learner](&makeLearner) without needing to create a new [Learner](&makeLearner) from scratch.
Here are some examples:

```{r}
## Change the ID
surv.lrn = setLearnerId(surv.lrn, "CoxModel")
surv.lrn

## Change the prediction type, predict a factor with class labels instead of probabilities
classif.lrn = setPredictType(classif.lrn, "response")

## Change hyperparameter values
cluster.lrn = setHyperPars(cluster.lrn, centers = 4)

## Go back to default hyperparameter values
regr.lrn = removeHyperPars(regr.lrn, c("n.trees", "interaction.depth"))
```

## Listing learners
See the [Appendix](integrated_learners.md) for a list of all learners integrated in [%mlr]
along with their respective properties.

If you would like a list of available learners with certain properties or suitable for a
particular learning [&Task], use function [&listLearners].

```{r}
## List everything in mlr
lrns = listLearners()
head(lrns[c("class", "package")])

## List classifiers that can output probabilities
lrns = listLearners("classif", properties = "prob")
head(lrns[c("class", "package")])

## List classifiers that can be applied to iris (i.e., multiclass) and output probabilities
lrns = listLearners(iris.task, properties = "prob")
head(lrns[c("class", "package")])

## The calls above return character vectors, but you can also create learner objects
head(listLearners("cluster", create = TRUE), 2)
```

