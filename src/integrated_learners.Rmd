---
params:
  full.code: FALSE
---
# Integrated Learners

This page lists the learning methods already integrated in [%mlr].

Columns **Num.**, **Fac.**, **Ord.**, **NAs**, and **Weights** indicate if a method can cope with
numerical, factor, and ordered factor predictors, if it can deal with missing values in a meaningful way
(other than simply removing observations with missing values) and if observation
weights are supported.

Column **Props** shows further properties of the learning methods specific to the
type of learning task.
See also [&RLearner] for details.

```{r include=FALSE}
library("mlr")
library("pander")
# baseR, urlBasePackages, urlContribPackages are defined in build
linkPkg = function(x) {
  x = strsplit(x, ",")[[1]]
  x = mlr:::cleanupPackageNames(x)    # remove exclamation marks
  if (urlBasePackages != urlContribPackages) {
    ind = x %in% baseR
    url = c(urlContribPackages, urlBasePackages)[ind + 1]
  } else {
    url = urlContribPackages
  }
  collapse(sprintf("[%1$s](%2$s%1$s/)", x, url), sep = "<br />")
}

getTab = function(type) {
  cn = function(x) if (is.null(x)) NA else gsub("\\n", " ", x)
  lrns = listLearners(type)
  lrns$note[is.na(lrns$note)] = ""
  cols = c("class", "type", "package", "short.name", "name", "numerics", "factors", "ordered", "missings", "weights", "note", "installed")
  props = setdiff(colnames(lrns), cols)

  colNames = c("Class / Short Name / Name", "Packages", "Num.", "Fac.", "Ord.", "NAs", "Weights", "Props", "Note")
  df = makeDataFrame(nrow = nrow(lrns), ncol = length(colNames),
    col.types = c("character", "character", "logical", "logical", "logical", "logical", "logical", "character", "character"))
  names(df) = colNames

  df[1] = apply(lrns[c("class", "short.name", "name")], 1, function(x)
    paste0("**", x["class"], "** <br /> *", cn(x["short.name"]), "* <br /><br />", cn(x["name"])))
  df$Packages = sapply(lrns$package, linkPkg)
  df[3:7] = lrns[c("numerics", "factors", "ordered", "missings", "weights")]
  df$Props = apply(lrns[props], 1, function(x) collapse(props[x], sep = "<br />"))
  df$Note = sapply(lrns$note, cn)
  logicals = vlapply(df, is.logical)
  df[logicals] = lapply(df[logicals], function(x) ifelse(x, "X", ""))
  df
}

makeTab = function(df) {
  pandoc.table(df, style = "rmarkdown", split.tables = Inf, split.cells = Inf,
    justify = c("left", "left", "center", "center", "center", "center", "center", "left", "left"))
}

types = c("classif", "multilabel", "regr", "surv", "cluster")
tables = lapply(types, getTab)
names(tables) = types
numbers = sapply(tables, nrow)
```

### Classification (`r numbers["classif"]`)
For classification the following additional learner properties are relevant and shown in
column **Props**:

* *prob*: The method can predict probabilities,
* *oneclass*, *twoclass*, *multiclass*: One-class, two-class (binary) or multi-class
  classification problems be handled,
* *class.weights*: Class weights can be handled.

```{r echo=FALSE,results="asis"}
makeTab(tables[["classif"]])
```

### Regression (`r numbers["regr"]`)
Additional learner properties:

* *se*: Standard errors can be predicted.

```{r echo=FALSE,results="asis"}
makeTab(tables[["regr"]])
```

### Survival analysis (`r numbers["surv"]`)
Additional learner properties:

* *prob*: Probabilities can be predicted,
* *rcens*, *lcens*, *icens*: The learner can handle right, left and/or interval censored data.

```{r echo=FALSE,results="asis"}
makeTab(tables[["surv"]])
```

### Cluster analysis (`r numbers["cluster"]`)
Additional learner properties:

* *prob*: Probabilities can be predicted.

```{r echo=FALSE,results="asis"}
makeTab(tables[["cluster"]])
```

### Cost-sensitive classification
For *ordinary misclassification costs* you can use all the standard classification methods listed
above.

For *example-dependent costs* there are several ways to generate cost-sensitive learners from
ordinary regression and classification learners.
See section [cost-sensitive classification](cost_sensitive_classif.md) and the documentation
of [&makeCostSensClassifWrapper], [&makeCostSensRegrWrapper] and [&makeCostSensWeightedPairsWrapper]
for details.

### Multilabel classification (`r numbers["multilabel"]`)
```{r echo=FALSE,results="asis"}
makeTab(tables[["multilabel"]])
```

Moreover, you can use the binary relevance method to apply ordinary classification learners
to the multilabel problem. See the documentation of function [&makeMultilabelBinaryRelevanceWrapper]
and the tutorial section on [multilabel classification](multilabel.md) for details.
